# -*- coding: utf-8 -*-
"""K Mean RFM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dLnxieAWZLVUvI60enCQBO-jS15q_ytJ

#<center>**Adventurework 2012 with Python**</center>
#<center>**K Mean RFM**</center>

**Data**: https://docs.microsoft.com/en-us/sql/samples/adventureworks-install-configure?view=sql-server-ver15&tabs=ssms

###**Library**
"""

# import library
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
import matplotlib.animation as animation
import matplotlib.pyplot as plt
from sklearn import datasets
import warnings
from datetime import datetime
from datetime import date
warnings.filterwarnings("ignore")

"""###**Load data**"""

# Load data from github
# File customer
url1 = 'https://raw.githubusercontent.com/syo2000/Adventurework-2012-with-Python/main/customer.csv'
df1 = pd.read_csv(url1)
df1.head()

# File factinternetsales
url2 = 'https://raw.githubusercontent.com/syo2000/Adventurework-2012-with-Python/main/factinternetsales.csv'
df2 = pd.read_csv(url2)
df2

"""###**Understanding data**

* Number of rows of columns data
* Descriptive statistics data
* Data overview

**Number of rows of columns data**
"""

# File customer
print("Rows:",f"{df1.shape[0]} instances")
print ("Columns:",f"{df1.shape[1]} attributes")

# File factinternetsales
print("Rows:",f"{df2.shape[0]} instances")
print ("Columns:",f"{df2.shape[1]} attributes")

"""**Descriptive statistics data**"""

# File customer
df1.describe()

# File factinternetsales
df2.describe()

"""**Data overview**"""

# File customer
df1.info()

# File factinternetsales
df2.info()

"""###**Remove columns**"""

# File customer
df1.drop(columns=['Title','Suffix','AddressLine2','SpanishEducation','FrenchEducation','SpanishOccupation','FrenchOccupation',
                  'GeographyKey.1','SpanishCountryRegionName','FrenchCountryRegionName','StateProvinceCode','StateProvinceName',
                  'CountryRegionCode','SpanishCountryRegionName','FrenchCountryRegionName','NameStyle','FirstName','MiddleName',
                  'LastName','PostalCode','IpAddressLocator','Phone','EmailAddress','AddressLine1','SalesTerritoryKey'], inplace=True)
df1.head()

# File factinternetsales
df2.drop(columns=['CarrierTrackingNumber','CustomerPONumber'], inplace=True)
df2.head()

"""###**Prepare data**

* Format
* Create RFM
* Check missing value
* Check duplicate
* Check outlier
* Histogram chart
* Fix Histogram chart
* Scaling the RFM data
"""

# Create dataframe new
X = df2[['CustomerKey','OrderDate','SalesOrderNumber', 'SalesOrderLineNumber','OrderQuantity', 'SalesAmount']]
X.head()

"""**Format**"""

# Convert OrderDate, DueDate to datatime
X['OrderDate'] = pd.to_datetime(df2['OrderDate'], errors='coerce')
X['DueDate'] = pd.to_datetime(df2['DueDate'], errors='coerce')

"""**RFM**

* Recency: How recently has the customer made a transaction with us
* Frequency: How frequent is the customer in ordering/buying some product from us
* Monetary: How much does the customer spend on purchasing products from us.
"""

# create Monetary
M = X
M = M.groupby(by='CustomerKey',as_index=False)['SalesAmount'].sum()
M.columns = ['CustomerKey','Monetary']
M.head()

# create Frequency
F = X
F = F.groupby(by='CustomerKey', as_index=False)['SalesOrderLineNumber'].nunique()
F.columns = ['CustomerKey','Frequency']
F.head()

#create Recency
R  = X[['CustomerKey','OrderDate']]
# Finding max data
maximum = max(R.OrderDate)
# Adding one more day to the max data, so that the max date will have 1 as the difference and not zero.
maximum = maximum + pd.DateOffset(days=1)
R['diff'] = maximum - R.OrderDate
R.head()

# recency by customerid
a = R.groupby('CustomerKey')

k = a['diff'].min()
k

# Dataframe merging by recency
df = pd.DataFrame(k)
df = df.reset_index()
df.columns = ["CustomerKey", "Recency"]
df.head()

#create RFM
RFM = F.merge(M, on = "CustomerKey")
RFM = RFM.merge(df, on = "CustomerKey")
RFM.head()

RFM.info()

# Format lại Recency từ datetime64 sang int
# Format Recency from datatime64 to int
RFM['Recency'] = RFM.Recency.dt.days

RFM.info()

"""**Missing value**"""

#thống kê theo missing value %
# Mising value
RFM.isnull().sum().sort_values(ascending=False)
for column in RFM.columns:
  per = RFM[column].isna().mean()
  print(f'{column}: {round(per*100,2)}%')

"""**Duplicate**"""

# Tìm dữ liệu bị duplicate
RFM.duplicated().sum()

"""**Outlier**"""

# outlier Monetary
sns.boxplot(RFM.Monetary)
Q1 = RFM.Monetary.quantile(0.25)
Q3 = RFM.Monetary.quantile(0.75)
IQR = Q3 - Q1
RFM = RFM[(RFM.Monetary >= (Q1 - 1.5*IQR)) & (RFM.Monetary <= (Q3 + 1.5*IQR))]

# outlier Frequency
sns.boxplot(RFM.Frequency)
Q1 = RFM.Frequency.quantile(0.25)
Q3 = RFM.Frequency.quantile(0.75)
IQR = Q3 - Q1
RFM = RFM[(RFM.Frequency >= Q1 - 1.5*IQR) & (RFM.Frequency <= Q3 + 1.5*IQR)]

# outlier Recency
sns.boxplot(RFM.Recency)
Q1 = RFM.Recency.quantile(0.25)
Q3 = RFM.Recency.quantile(0.75)
IQR = Q3 - Q1
RFM = RFM[(RFM.Recency >= Q1 - 1.5*IQR) & (RFM.Recency <= Q3 + 1.5*IQR)]

"""**Histogram chart**"""

for i in RFM:
    sns.distplot(RFM[i])
    plt.show()

"""**Fix skewed chart**"""

# Fix RFM
RFM['Monetary'] = np.log(RFM['Monetary']+1) #+1 cause the log here takes a negative value
RFM['Recency'] = np.log(RFM['Recency']+1)

for i in RFM:
    sns.distplot(RFM[i])
    plt.show()

"""**Scaling the RFM data - Chuẩn hóa**"""

# standardise all parameters
RFM_norm1 = RFM.drop(["CustomerKey"], axis=1)

from sklearn.preprocessing import StandardScaler
standard_scaler = StandardScaler()
RFM_norm1 = standard_scaler.fit_transform(RFM_norm1)

RFM_norm1 = pd.DataFrame(RFM_norm1)
RFM_norm1.columns = ['Frequency','Amount','Recency']
RFM_norm1.head()

"""### **Find the optimal number of clusters**"""

# import library
from sklearn.cluster import KMeans


#fit KMeans and calculate SSE for each K
sse = {}
for k in range(1,11):
	kmeans = KMeans(n_clusters = k, random_state=1)
	kmeans.fit(RFM_norm1)
	sse[k] = kmeans.inertia_ 

#plot SSE for each K
plt.title('The Elbow Method')
plt.xlabel('K'); plt.ylabel('SSE')
sns.pointplot(x=list(sse.keys()), y=list(sse.values()))
plt.show()

"""### **K mean**"""

#Thuật toán K mean
# Kmean
def kmeans(normalised_df_rfm, clusters_number, original_df_rfm):
    
    kmeans = KMeans(n_clusters = clusters_number, random_state = 1)
    kmeans.fit(normalised_df_rfm)

     #Extract cluster labels
    cluster_labels = kmeans.labels_
        
     #Create a cluster label column in original dataset
    df_new = original_df_rfm.assign(Cluster = cluster_labels)  
    return df_new

df_rfm_k4 = kmeans(RFM_norm1, 4, RFM)

# Chart scatter 3 chiều
# Chart scatter 3D
import plotly.express as px
from plotly.offline import iplot
def chartkmean(k): 
  fig = px.scatter_3d(k, x='Recency', 
                   y='Frequency', z='Monetary', 
                   color='Cluster')
  iplot(fig)

plt.subplot(4, 1, 2)
chartkmean(df_rfm_k4)

"""**Analyzing average RFM values of each cluster**"""

def rfm_values(df):

    df_new = df.groupby(['Cluster']).agg({
        'Recency': 'mean',
        'Frequency': 'mean',
        'Monetary': ['mean', 'count']
    }).round(0)
    
    return df_new

rfm_values(df_rfm_k4)

# Thông tin các khách hàng ở cụm thứ 4
# Information of customers in the 4th cluster
df_rfm_k4[df_rfm_k4['Cluster'] == 3]

# Information of customers with ID 11015
df1[df1['CustomerKey'] == 11015	]